# Chapter 8: Unsupervised Entity Alignment

> *Entity Alignment: Concepts, Recent Advances and Novel Approaches*
> - https://link.springer.com/chapter/10.1007/978-981-99-4250-3_1 (page 213)

## Abstract
1. **研究背景**：最新的实体对齐（Entity Alignment, EA）解决方案往往依赖于有标签的数据进行模型训练。此外，它们通常在封闭域（closed-domain）下工作，无法处理不可对齐的实体。
2. **研究动机**：为了解决这些不足，我们提出了一个在开放世界中执行实体对齐的无监督框架。
3. **方法概述**：
   - 首先，我们从知识图谱（Knowledge Graph, KG）的辅助信息中挖掘有用特征。
   - 接着，设计一个不可对齐实体预测模块，以筛除不可对齐的实体并产生初步对齐结果。
   - 这些初步结果被视为伪标签数据，并被输入到渐进学习框架中，以生成结构化表示，并与辅助信息相结合，提供更全面的对齐视角。
   - 最终，渐进学习框架通过逐渐提高结构化嵌入的质量，并通过上一轮的对齐结果丰富伪标签数据，从而提高对齐性能。
4. **研究贡献**：我们的解决方案不需要有标签数据，且能够有效过滤掉不可对齐的实体。综合实验评估验证了其优越性。

## 8.1 Introduction

1. **现有方法的局限性**：
   - 现有最先进的EA解决方案 [2–5] 假设等价实体通常具有相似的邻域信息。
   - 因此，它们利用KG嵌入模型（如TransE [6]）或图神经网络（GNN）模型（如GCN [7]）来生成单个KG中实体的结构嵌入。
   - 然后，通过使用种子实体对作为连接，将这些独立的嵌入投影到统一的嵌入空间中，使得来自不同KG的实体可以直接比较。
   - 最终，为了确定对齐结果，大多数当前工作 [1, 8–10] 将对齐过程形式化为排序问题，即对源KG中的每个实体，根据某种距离度量对目标KG中的所有实体进行排序，距离最小的实体被视为等价的目标实体。

2. **示例**：
   - 图8.1是关于导演是是枝裕和的部分英文KG和部分西班牙KG，其中虚线表示已知的对齐关系（即种子）。
   - EA任务旨在识别两个KG之间的等价实体对，例如（Shoplifters, Manbiki Kazoku）。

<figure style="display: block; text-align: center;">   <img src="FL/2024_11_12/images/2024-11-27-19-23-19.png" at="name" style="display: block; margin: auto; width: 50%; height: auto;"> </figure>

1. **现有方法的几个问题**：
   - **对有标签数据的依赖**：大多数方法依赖于预对齐的种子实体对来连接两个KG，并使用统一的KG结构嵌入来对齐实体。然而，这些有标签数据在现实环境中可能并不存在。例如，在示例中，KGEN中的是枝裕和与KGES中的是枝裕和之间的等价关系可能事先未知。在这种情况下，仅依赖结构信息的最新方法将无法胜任，因为没有种子来连接这些独立的KG。
   - **封闭域设置**：所有现有EA解决方案都在封闭域设置下工作 [11]，即假设源KG中的每个实体在目标KG中都有一个等价实体。然而，在实际环境中，总是存在不可对齐的实体。例如，在示例中，对于源实体Ryo Kase，目标KG中没有等价实体。因此，理想的EA系统应该能够预测不可对齐的实体。

2. **我们的无监督EA解决方案：UEA**：
   - 为了应对这些问题，我们提出了一个能够解决不可对齐问题的无监督EA解决方案UEA。
   - 具体而言，为了减少对有标签数据的依赖，我们从KG的辅助信息中挖掘有用特征，并用它们生成初步的伪标签数据。
   - 这些初步的种子被输入到我们设计的渐进学习框架中，以生成统一的KG结构表示，并与辅助信息结合，提供更全面的对齐视角。
   - 该框架还通过自训练方式逐步增强训练数据并提高对齐结果。此外，为了处理不可对齐问题，我们设计了一个不可对齐实体预测模块，该模块利用阈值化双向最近邻搜索（TBNNS）筛除不可对齐的实体，并将其排除在对齐结果之外。
   - 我们将不可对齐实体预测模块嵌入到渐进学习框架中，通过动态调整TBNNS中的阈值来控制渐进学习的进度。

3. **伪标签数据的信度（Confidence）**：
   - 此外，考虑到渐进学习过程中生成的伪标签数据质量可能存在差异，我们引入了信度的概念来衡量实体对是否正确的概率。
   - 我们进一步将这些信度分数融入到KG表示学习中，以产生更准确的结构嵌入。
   - 通过实证研究，我们证明了基于信度的框架CUEA比UEA在输入辅助信息质量不同的情况下具有更稳定的性能。

### Contribution
本章的主要贡献可以总结如下：

- **识别现有EA方法的不足**：我们识别了现有EA方法的不足，即需要有标签数据并在封闭域环境下工作，并提出了一个无监督EA框架UEA，以及一个基于信度的扩展模型CUEA，能够处理不可对齐的实体。具体来说：
  1. 利用KG的辅助信息生成初步伪标签数据；
  2. 设计了一个不可对齐实体预测模块，利用基于信度的阈值双向最近邻搜索（TBNNS）策略生成对齐结果，有效排除不可对齐的实体；
  3. 提供了一种渐进学习算法，以提高KG嵌入的质量并增强对齐性能。
- **实验验证**：我们通过实证评估将我们的提案与最先进的方法进行了比较，结果证明了它们的优越性。

### Organization
- **Section 8.2**：正式定义EA任务并介绍相关工作。
- **Section 8.3**：详细阐述框架。
- **Section 8.4**：介绍实验结果并进行详细分析。
- **Section 8.5**：总结本章内容。

## 8.2 Task Definition and Related Work

1. **Task Definition（任务定义）**
   - EA任务的输入是源KG \(G_1\) 和目标KG \(G_2\)。
   - EA的任务被定义为在KG之间找到等价实体，即 \(A = \{(u, v) | u \in E_1, v \in E_2, u \leftrightarrow v\}\)，其中 \(E_1\) 和 \(E_2\) 分别表示 \(G_1\) 和 \(G_2\) 的实体集，\(u \leftrightarrow v\) 表示源实体 \(u\) 和目标实体 \(v\) 等价，即 \(u\) 和 \(v\) 代表相同的现实世界对象。
   - 大多数现有的EA解决方案假设存在一组种子实体对 \(s = \{(u_s, v_s) | u_s \in E_1, v_s \in E_2, u_s \leftrightarrow v_s\}\)。然而，在本章中，我们关注无监督EA，不假设这些有标签数据的可用性。

2. **Unsupervised Entity Alignment（无监督实体对齐）**
   - 一些方法已经研究了无标签数据情况下的对齐问题。Qu等人 [20] 提出了一种基于对抗训练框架(Adversarial Training Framework)的无监督知识图谱对齐方法。然而，其实验结果非常差强人意。
   - He等人 [21] 利用异构KG之间的共享属性来生成对齐的实体对，用于检测更多等价的属性。他们交替执行实体对齐和属性对齐，生成更多高质量的对齐实体对，这些对齐实体对被用于训练关系嵌入模型。最后，他们通过二元回归模型将由属性和关系三元组生成的对齐结果结合在一起。
     - 这项工作的整体流程可能看起来与我们提出的模型相似。然而，存在许多显著的不同，例如，我们的工作中的KG嵌入是逐步更新的，这可以得到更准确的对齐结果，且我们的模型可以处理不可对齐的实体。在第8.4节中，我们通过实验证明了我们模型的优越性。
   - 我们注意到，一些实体解析（Entity Resolution, ER）方法也建立在类似于EA的环境中，以PARIS [22] 为代表。它们采用集体对齐算法，例如相似性传播（similarity propagation），以对实体之间的关系进行建模。我们在实验研究中也包括了它们，以确保本章的全面性。
     > - 集体对齐算法（Collective Alignment Algorithm）：集体对齐算法是一种用于实体解析的方法，它通过集体对齐（Collective Alignment）来识别和连接具有相同含义的实体。集体对齐算法通常包括以下几个步骤：
       > 1. 初始化：为每个实体分配一个初始标签或表示。
       > 2. 相似性传播：通过迭代过程，实体根据它们之间的相似性传播标签或表示。
       > 3. 聚类：根据传播的标签或表示，将实体分组为等价的实体对。
       > 4. 验证：对聚类结果进行验证和调整，以确保结果的准确性和可靠性。

## 8.3 Methodology

在本节中，我们首先介绍我们提出的方法的概要。然后，详细说明如何处理辅助信息以生成初步的对齐种子。

### 8.3.1 Model Outline（模型概要）

- 如图8.2所示，给定两个知识图谱（KGs），CUEA首先从辅助信息中挖掘有用的特征。
- 这些特征被传递到不可对齐实体预测模块，以生成具有信度得分的初始对齐结果，作为伪标签数据。
- 然后，渐进学习框架使用这些伪种子及其概率得分来连接两个KG，并学习统一的实体结构嵌入。
- 它进一步结合来自辅助信息和结构信息的对齐信号，为对齐提供更全面的视角。
- 最终，通过迭代更新伪标签数据，渐进地提高结构嵌入的质量并丰富对齐结果，从而逐步获得更好的对齐。
- 注意，通过将信度得分设为1，CUEA可以变为UEA模型。

<figure style="display: block; text-align: center;">   <img src="FL/2024_11_12/images/2024-11-27-19-44-16.png" at="name" style="display: block; margin: auto; width: 50%; height: auto;"> </figure>

### 8.3.2 Side Information（辅助信息）

- KG中有丰富的辅助信息，例如属性、描述和类。在本章中，我们使用属性的一种特定形式——实体名称，因为它存在于大多数KG中。
- 为了最大化利用实体名称信息，受到Zeng等人 [5] 的启发，我们从语义层面和字符串层面挖掘这些信息，并生成两个KG中实体之间的文本距离矩阵。
- 具体来说，我们使用平均词嵌入来表示实体名称的语义含义。给定源实体和目标实体的语义嵌入，通过从1减去它们的余弦相似度得分来获得语义距离得分。
- 我们将两个KG中实体之间的语义距离矩阵记为 \(M_n\)，其中行代表源实体，列代表目标实体，矩阵中的每个元素表示源实体与目标实体之间的距离得分。
- 至于字符串级特征，我们采用Levenshtein距离 [23] 来衡量两个序列之间的差异。我们将字符串距离矩阵记为 \(M_l\)。
- 为了获得对齐的更全面视角，我们将这两个距离矩阵结合起来，生成文本距离矩阵 \(M_t = \alpha M_n + (1 - \alpha) M_l\)，其中 \(\alpha\) 是权衡权重的超参数。
- 然后，我们将文本距离矩阵 \(M_t\) 传递给不可对齐实体模块，生成对齐结果，作为训练KG结构嵌入的伪标签数据。详细内容将在下一小节中介绍。

**Remark**：这一步的目的是利用可用的辅助信息生成对齐的有用特征。其他类型的辅助信息，例如属性和实体描述，也可以被利用。此外，还可以使用更先进的文本编码器，例如拼写无关词嵌入 [24] 和用于编辑距离的卷积嵌入 [25]。我们将在未来研究它们。

### 8.3.3 Unmatchable Entity Prediction（不可对齐实体预测）

- 最新的EA解决方案为每个源实体生成一个对应的目标实体，而未考虑潜在的不可对齐问题。
- 然而，正如[12]中提到的，在现实环境中，KG包含其他KG不包含的实体。例如，在对齐YAGO 4和IMDB时，YAGO 4中的实体只有1%与电影相关，而其他99%的实体在IMDB中没有匹配。这些不可对齐的实体会增加EA的难度。
- 因此，在本章中，我们设计了一个不可对齐实体预测模块，以预测不可对齐的实体并将其从对齐结果中过滤掉。

#### 8.3.3.1 Thresholded Bidirectional Nearest Neighbor Search（阈值双向最近邻搜索）

- 我们提出了一种新的策略，即阈值双向最近邻搜索（TBNNS），用于生成对齐结果，并预测未对齐的实体为不可对齐实体。
- 如算法1所示，给定源实体 \(u\) 和目标实体 \(v\)，如果 \(u\) 和 \(v\) 互为最近邻，且它们之间的距离小于给定阈值 \(\theta\)，我们认为 \((u, v)\) 是一个对齐实体对。注意，\(M(u, v)\) 表示距离矩阵 \(M\) 中第 \(u\) 行和第 \(v\) 列的元素。
- TBNNS策略对对齐施加了严格的约束，因为它要求匹配的实体双方都最优选彼此，且它们嵌入之间的距离低于一定值。因此，它可以有效预测不可对齐的实体，防止它们被对齐。
- 值得注意的是，阈值 \(\theta\) 在这个策略中起着重要作用。较大的阈值会导致更多的匹配，但也会增加包含错误匹配或不可对齐实体的风险。相反，较小的阈值只会产生少量对齐实体对，但几乎所有的对齐都是正确的。这在第8.4.4节中进一步讨论和验证。因此，我们的渐进学习框架动态调整阈值，以生成更准确的对齐结果（将在下一小节中讨论）。

<figure style="display: block; text-align: center;">   <img src="FL/2024_11_12/images/2024-11-27-19-43-45.png" at="name" style="display: block; margin: auto; width:100%; height: auto;"></figure>

#### 8.3.3.2 Confidence-Based TBNNS（信度基础的TBNNS）

1. **背景与动机**：
   - 考虑到由TBNNS生成的对齐实体对具有不同的质量（即，有些是正确的，有些则不是），我们进一步提出了基于信度的TBNNS（C-TBNNS），用于衡量实体对的信度（即其为正确的概率）。

2. **信度得分的定义**：
   - 我们定义实体对 \((u, v)\) 的信度得分为：
     \[
     C(u, v) = M(u, v') - M(u, v) + M(v, u') - M(v, u)
     \]
     - 其中，\(\Delta_1 = M(u, v') - M(u, v)\) 表示与实体 \(u\) 距离最近的两个实体（即 \(v\) 和 \(v'\)）之间距离得分的差距；
     - \(\Delta_2 = M(v, u') - M(v, u)\) 表示与实体 \(v\) 距离最近的两个实体（即 \(u\) 和 \(u'\)）之间距离得分的差距。
   - 直观上，如果实体对 \((u, v)\) 的两边距离都是最小的，且前两个候选项之间的距离有较大的差距，那么将其视为正确实体对的信度更高。

3. **信度得分的范围限制**：
   - 我们进一步将信度得分限制在一定范围内：
     \[
     C(S) = (1 - \lambda) \frac{C(S) - \min\{C(S)\}}{\max\{C(S)\} - \min\{C(S)\}} + \lambda
     \]
     - 其中，\(C(S)\) 表示集合 \(S\) 中实体对的信度得分。
     - 公式的核心是**最小-最大归一化**（min-max normalization），将信度得分转换为 \([0, 1]\) 之间。我们添加了超参数 \(\lambda \in [0, 1]\) 来进一步限制信度得分的范围为 \([\lambda, 1]\)。
     - 通过将 \(\lambda\) 设置为1，所有实体对将具有相同的信度得分为1，C-TBNNS可以还原为TBNNS。因此，C-TBNNS可以视为TBNNS的一般情况，它将信度（概率）的概念引入到对齐结果的生成过程中。

### 8.3.4 The Progressive Learning Framework（渐进学习框架）

1. **目标**：
   - 为了利用KG中丰富的结构模式提供对齐信号，我们设计了一个渐进学习框架，将结构特征和文本特征结合起来进行对齐，并通过自训练方式提高结构嵌入和对齐结果的质量。

#### 8.3.4.1 Knowledge Graph Representation Learning（知识图谱表示学习）

1. **初步对齐与伪标签数据**：
   - 如上所述，我们将利用辅助信息生成的文本距离矩阵 \(M_t\) 传递给不可对齐实体预测模块，以产生初步对齐结果，作为学习统一KG嵌入的伪标签数据。
   - 具体地，遵循 [18]，我们采用GCN1来捕捉实体的邻域信息。由于实现细节不是本文的重点，可以在 [18] 中找到相关内容。

2. **对齐目标**：
   - 由于源KG和目标KG的表示是单独学习的，因此需要将它们投影到统一的嵌入空间，以便可以直接比较跨KG的实体。
   - 为此，我们使用半监督损失函数来强制标签实体对中实体的嵌入之间的距离尽量小，同时使负样本（即不等价的实体对）之间的距离尽量大。形式化表达如下：
     \[
     L = \sum_{(u, v) \in S} \sum_{(u', v') \in S'_{(u,v)}} [d(u, v) + \gamma - d(u', v')]_+
     \]
     - 其中 \([·]_+ = \max\{0, ·\}\)，\((u, v)\) 是训练数据中的一个标签实体对，\(S'_{(u,v)}\) 表示通过最近邻采样 [1] 获得的负样本实体对集。
     - \(u\) 和 \(v\) 分别表示由GCN学习的源实体和目标实体的嵌入，\(d(·, ·)\) 是测量两个嵌入之间距离的函数，\(\gamma\) 是用于分离正样本与负样本的超参数。

3. **信度基础的目标**：
   - 考虑到伪标签实体对具有不同的信度，我们将这些概率融入到对齐目标中，以学习更准确的结构嵌入：
     \[
     L_c = \sum_{(u, v) \in S} \sum_{(u', v') \in S'_{(u,v)}} C(u, v) \ast [d(u, v) + \gamma - d(u', v')]_+
     \]
     - 其中 \(C(u, v)\) 是附加到每个实体对上的信度得分。
     - 因此，信度更高的实体对将在训练过程中发挥更重要的作用，而信度较低的伪实体对则对训练的影响较小，从而减轻错误对齐的影响。

4. **特征融合**：
   - 给定学习到的结构嵌入矩阵 \(Z\)，我们通过从1减去嵌入之间的余弦相似度来计算源实体和目标实体之间的结构距离得分。我们将得到的结构距离矩阵记为 \(M_s\)。
   - 然后，我们结合文本和结构信息以生成更准确的对齐信号：\(M = \beta M_t + (1 - \beta) M_s\)，其中 \(\beta\) 是权衡权重的超参数。
   - 融合后的距离矩阵 \(M\) 可用于生成更准确的匹配。

#### 8.3.4.2 The Progressive Learning Algorithm（渐进学习算法）

1. **渐进数据增强与伪标签生成**：
   - 训练数据的数量会影响统一KG嵌入的质量，从而影响对齐性能 [3, 26]。
   - 因此，我们设计了一种算法（算法2）来逐步增加伪训练数据，以提高KG嵌入的质量并增强对齐性能。
   - 算法首先使用初步伪标签数据 \(S_0\) 学习统一的结构嵌入并生成融合距离矩阵 \(M\)（第1-2行）。然后，利用融合距离矩阵通过C-TBNNS生成新的对齐结果 \(\Delta S\)（第4行）。
   - 这些新生成的实体对 \(\Delta S\) 被添加到对齐结果中，接下来用于生成下一轮的融合距离矩阵（第6-7行）。\(S\) 中的实体从实体集中移除（第9-10行）。
   - 为了逐步提高KG嵌入的质量并检测更多的对齐结果，我们递归地执行上述过程，直到新生成的实体对数量低于给定阈值 \(\mu\)。最后，我们将集合 \(S\) 中的实体对视为最终的对齐结果。

2. **逐步减少对齐搜索空间**：
   - 值得注意的是，在学习过程中，一旦一对实体被认为是匹配的，实体将从实体集中移除（第5-6行和第12-13行）。
   - 这种策略可以逐渐减少对齐搜索空间，降低对齐其余实体的难度。当然，该策略存在错误传播的问题，但可以通过动态调整阈值的渐进学习过程来有效减轻。

### 8.3.4.3 Dynamic Threshold Adjustment（动态阈值调整）

1. **背景与挑战**：
   - 从算法2可以看出，由不可对齐实体预测模块生成的匹配不仅是最终对齐结果的一部分，也是用于学习后续结构嵌入的伪训练数据的一部分。因此，为了提高整体的对齐性能，每一轮生成的对齐结果理想情况下应同时具有大量的数量和高质量。然而，这两个目标无法同时实现。
   - 这是因为，如在8.3.3节所述，在TBNNS中使用较大的阈值可以生成更多的对齐结果（数量大），但其中一些可能是错误的（质量低）。这些错误对齐的实体对可能导致错误传播问题，从而导致后续轮次中出现更多错误的匹配。
   - 相反，较小的阈值会导致对齐结果较少（数量少），但几乎所有的结果都是正确的（质量高）。

2. **解决方法**：
   - 为了解决这个问题，我们的目标是在每一轮生成的匹配中平衡数量和质量。一个直观的想法是将阈值设置为一个中等值，但这未能考虑到渐进学习过程的特征。
     - 在一开始，应该优先考虑匹配的质量，因为这些对齐结果对后续轮次将产生长期影响。
     - 相比之下，在后期阶段，当大多数实体已被对齐时，数量更为重要，因为我们需要包括更多可能的匹配，这些匹配可能没有较小的距离得分。
   - 基于此，我们将初始阈值 \(\theta_0\) 设置为一个非常小的值，以减少潜在的错误。然后，在后续轮次中，我们逐渐增加阈值 \(\eta\)，以便检测到更多可能的匹配。我们将在8.4.3节中通过实验验证这种策略优于固定权重。

3. **信度基础框架的帮助**：
   - 值得注意的是，我们提出的基于信度的框架CUEA可以进一步帮助缓解低质量问题，因为我们对每个实体对计算并分配了一个信度得分，错误对齐的实体对将被假定为具有较低的信度得分，从而对随后的对齐过程影响较小。

4. **备注**：
   - 如在相关工作中提到的，有一些现有的EA方法利用迭代学习（自举）策略来提高EA性能。特别是，BootEA为每个源实体计算与每个目标实体的对齐可能性，并将可能性高于给定阈值的匹配包括在最大可能性匹配过程中（在1对1映射约束下），生成包含可信EA对的解决方案 [15]。该策略也被[8, 16]采用。Zhu等人使用阈值选择具有非常接近距离的实体对作为伪标签数据 [14]。DAT使用基于边界的双向约束选择可信EA对作为标签 [17]。
   - 我们的渐进学习策略与这些现有的解决方案有三个不同之处：
     1. 我们将可信EA对中的实体从测试集中排除；
     2. 我们使用动态阈值调整策略来控制学习过程的进度；
     3. 我们的策略可以处理不可对齐的实体；
     4. 我们为每个选定的实体对附加了一个信度得分，这可以减轻错误对正对KG表示学习过程及对齐结果的负面影响。
   - 我们将在8.4.3节中验证我们策略的优越性。


### 8.4 实验 (Experiment)
本节报告了实验结果并进行了深入分析。源代码可以在 https://github.com/DexterZeng/UEA 获得。

#### 8.4.1 实验设置 (Experimental Settings)
**数据集**：根据现有研究，我们采用了 DBP15K 数据集 [3] 进行评估。该数据集包含从 DBpedia 中提取的三个多语言知识图谱（KG）对。每个 KG 对包含 15,000 个跨语言链接作为黄金标准。相关统计数据可以在表 8.1 中找到。我们注意到，现有的最先进研究仅考虑标记实体并将其分为训练集和测试集。然而，正如表 8.1 所示，存在未标记的实体，例如 DBP15KZH-EN 中中文和英文 KG 各有 4,388 和 4,572 个未标记实体。为此，我们通过引入不可对齐实体来调整数据集。具体来说，对于每个 KG 对，我们保留 30% 的标记实体对作为训练集（用于训练监督或半监督方法）。然后，构建测试集时，我们包含第一个 KG 中其余的实体以及第二个 KG 中剩余的标记实体，从而使第一个 KG 中的未标记实体成为不可对齐的实体。测试集的统计数据可以在表 8.1 的“测试集”列中找到。

**参数设置**：对于辅助信息模块，我们使用了 fastText 嵌入 [27] 作为词嵌入。为了处理跨语言 KG 对，按照 [19]，我们使用 Google Translate 将实体名称从一种语言翻译到另一种语言，例如将中文、日文和法文翻译为英文。α 设置为 0.5。对于结构信息学习，我们设置 β 为 0.5。根据 [18]，我们将对齐目标中的 γ 设置为 3，并采用曼哈顿距离作为距离函数 d(·, ·)。对于 C-TBNNS，我们设置 λ 为 0.4。对于渐进学习，我们将初始阈值 θ0 设置为 0.05，增量参数 η 设置为 0.1，终止阈值 γ 设置为 30。注意，如果阈值 θ 超过 0.45，我们将其重置为 0.45。这些超参数是默认值，因为没有额外的验证集用于超参数调优。

**评估指标**：我们使用精确率 (P)、召回率 (R) 和 F1 分数作为评估指标。精确率计算为方法找到的匹配数中正确匹配的比例。召回率计算为黄金标准中正确匹配的比例。F1 分数是精确率和召回率之间的调和平均数。表格中加粗的数字代表最佳结果。

**竞争对手**：我们选择了最先进的解决方案进行比较。在只利用结构信息的组中，我们与 BootEA [15]、TransEdge [8]、MRAEA [26] 和 SSP [28] 进行了比较。在使用其他信息的方法中，我们与 GCN-Align [18]、HMAN [9]、HGCN [4]、RE-GCN [29]、DAT [17] 和 RREA [30] 进行了比较。我们还包括了无监督方法，如 IMUSE [21] 和 PARIS [22]。为了公平比较，我们仅使用实体名称标签作为辅助信息。

<figure style="display: block; text-align: center;">   <img src="FL/2024_11_12/images/2024-12-02-13-35-46.png" at="name" style="display: block; margin: auto; width: 50%; height: auto;">  </figure>

#### 8.4.2 实验结果 (Results)
表 8.2 报告了对齐结果，表明最先进的监督或半监督方法的精确率值相对较低。这是因为这些方法无法预测不可对齐的源实体，并为每个源实体（包括不可对齐的实体）生成一个目标实体。特别是，结合额外信息的方法比只使用结构信息的方法表现更好，表明利用这些附加信息的好处。

对于无监督方法，虽然 IMUSE 无法处理不可对齐的实体，并且精确率较低，但在召回率和 F1 分数方面，其表现优于大多数监督或半监督方法。这表明，对于 EA 任务，KG 的辅助信息对于缓解对标记数据的依赖性非常有用。与上述方法不同，PARIS 达到了非常高的精确率，因为它只生成它认为高度可能的匹配，这有效地过滤掉了不可对齐的实体。它在所有方法中获得了第二高的 F1 分数，展示了其在涉及不可对齐实体时的有效性。我们的提议 UEA 和 CUEA 在精确率和召回率之间取得了最佳平衡，获得了最佳 F1 分数，超出第二名很大幅度，验证了它们的有效性。值得注意的是，尽管我们提出的模型不需要标记数据，但它们比最先进的监督方法（如 HMAN 和 DAT）表现更好。

此外，通过将信心概念引入 UEA，CUEA 取得了与 UEA 相当的结果。乍一看，似乎为实体对分配置信分数对表示学习和对齐结果没有很大影响，但这可能是因为这些数据集上的辅助信息非常有效（仅使用字符串信息可以获得 0.814 的 F1 分数，见表 8.4），因此使得结构信息（受置信分数影响较大）对整体结果的贡献较少。接下来，我们将展示置信框架在辅助信息质量较低的数据集上的更大作用。

#### 8.4.2.1 使用低质量辅助信息的结果 (Results Using Low-Quality Side Information)
我们在辅助信息质量较低的实际场景下比较了无监督方法。具体来说，我们假设没有可用的预训练词嵌入和机器翻译工具。在这种情况下，使用实体名称信息的一种可行方法是直接比较名称字符串。然而，对于跨语言数据集，如 DBP15KZH-EN 和 DBP15KJA-EN，源 KG 和目标 KG 的语言不一致，直接字符串比较是无效的。因此，我们旨在检查在辅助信息质量较低且无法为对齐提供有用信号的情况下，这些无监督方法的有效性。

我们在表 8.3 中报告了 DBP15KZH-EN 和 DBP15KJA-EN 的结果，其中直接比较实体名称字符串作为辅助信息。可以看出，所有方法的 F1 分数都很低（相比表 8.2 中的结果），表明辅助信息的质量确实会影响整体对齐结果。此外，在低质量辅助信息的情况下，我们提出的 UEA 和 CUEA 模型仍在 F1 分数方面优于基线方法 IMUSE 和 PARIS，证明了渐进学习框架和不可对齐实体预测模块的有效性。此外，值得注意的是，CUEA 在所有指标上均优于 UEA。这可能归因于基于置信的对齐结果生成过程，这使得具有较高置信度的实体对（可能更正确）在表示学习和对齐过程中的影响更大。


### 8.4.3 消融研究 (Ablation Study)
在本节中，我们通过进行消融研究来验证所提出模块的有用性。具体而言，在表8.4中，我们报告了不包含不可对齐实体预测模块的UEA（UEA w/o Unm）和不包含渐进学习过程的UEA（UEA w/o Prg）的结果。结果显示，去掉不可对齐实体预测模块（UEA w/o Unm）会使所有指标和数据集的表现下降，这验证了其在检测不可对齐实体并增强整体对齐性能方面的有效性。此外，如果没有渐进学习模块（UEA w/o Prg），精确度（precision）有所提升，但召回率（recall）和F1值显著下降。这表明渐进学习框架可以发现更多正确的对齐实体对，是对齐过程中的关键部分。

为了提供对渐进学习框架的深入了解，我们报告了没有调整阈值的UEA（UEA w/o Adj）和在渐进学习过程中没有从实体集中排除对齐结果中的实体的UEA（UEA w/o Excl）的结果。表8.4显示，将阈值设为固定值（UEA w/o Adj）会导致F1结果变差，这验证了渐进学习过程依赖于阈值的选择和对齐结果的质量。我们将在下一节中进一步讨论阈值的设置。此外，如果不从实体集中排除已匹配的实体（UEA w/o Excl），性能也会下降，这表明这种策略确实可以降低实体对齐的难度。

此外，我们将渐进学习框架替换为其他最先进的迭代学习策略（例如MWGM [15]，TH [14]，和DAT-I [17]）并在表8.4中报告了结果。结果显示，使用我们的渐进学习框架（UEA）可以获得最佳的F1分数，验证了其优越性。

### 8.4.4 定量分析 (Quantitative Analysis)
在本节中，我们对UEA和CUEA中的模块进行了定量分析。

#### TBNNS中的阈值θ
我们讨论了θ的设置，以揭示在渐进学习中生成对齐结果时的风险和收益之间的权衡。识别到一个匹配意味着可以整合额外的结构信息，这有利于后续的学习。然而，同样地，错误识别，即错误匹配，可能会导致错误修改KG之间的连接，存在放大随后的错误的风险。如图8.3所示，较小的阈值θ（例如0.05）带来的风险低，收益也低；即，它只会生成少量匹配，并且其中几乎全部是正确的。相反，较高的阈值θ（例如0.45）增加了风险，同时带来相对较高的收益；即，生成的对齐实体对更多，但其中有一部分是错误的。此外，使用较高的阈值会带来越来越多的对齐结果，而较低的阈值则使渐进学习过程几乎不会增加匹配数量。这与我们在8.3.3节中的理论分析一致。

#### 不可对齐实体预测
赵等人（Zhao et al.）[12] 提出了一种直观的策略（U-TH）来预测不可对齐的实体。他们设置了一个NIL阈值，如果源实体与其最接近的目标实体之间的距离值高于此阈值，他们就认为该源实体是不可对齐的。我们通过对最终对齐结果中包含的不可对齐实体的百分比和F1分数进行比较，以评估我们的不可对齐实体预测策略。在DBP15KZH-EN上，将我们的不可对齐实体预测策略替换为U-TH的F1分数为0.837，比UEA低了8.4%。此外，使用U-TH生成的对齐结果中有18.9%的实体是不可对齐的，而UEA的这一数字仅为3.9%。这证明了我们的不可对齐实体预测策略的优越性。

#### 参数的影响
如8.4.1节所述，我们将α和β都设置为0.5，因为没有训练/验证数据。这里，我们旨在证明不同的参数值对最终结果的影响不大。具体来说，我们将α保持在0.5，选择β为[0.3, 0.4, 0.5, 0.6, 0.7]；然后将β保持在0.5，选择α为[0.3, 0.4, 0.5, 0.6, 0.7]。从图8.4中可以看出，尽管较小的α和β可以带来更好的结果，但性能并没有显著变化。

#### CUEA中的超参数λ
接着，我们分析了公式(8.2)中的超参数λ对最终对齐结果的影响，λ决定了信度得分的范围。为了突出其对结构表示学习的影响，我们按照8.4.2.1节中的设置，并在表8.5中报告了结果。

从表8.5中可以看出，当λ不是特别大时，对齐性能相对稳定。然而，当λ设为较大值（例如1，即还原为UEA）时，结果大幅下降。这表明，根据实体对的真实度为其分配概率得分可以促进对齐。此外，一般来说，CUEA对λ的变化具有较强的鲁棒性（只要λ不太大）。

#### 输入的辅助信息的影响
我们采用不同的辅助信息作为输入，来检查UEA的性能。具体而言，我们报告了仅使用实体名称的字符串级特征作为输入的UEA-Ml，以及仅使用实体名称的语义嵌入作为输入的UEA-Mn的结果。我们还提供了仅使用字符串级和语义信息直接生成对齐结果（没有渐进学习）的Ml和Mn的结果。

如表8.3所示，单独使用输入辅助信息的性能并不理想（Ml和Mn）。然而，通过将辅助信息输入到我们的模型中，UEA-Ml和UEA-Mn的结果变得更好。这揭示了UEA可以处理不同类型的辅助信息并不断改进对齐结果。此外，通过比较UEA-Ml和UEA-Mn，可以看出输入的辅助信息确实会影响最终结果，并且辅助信息的质量对于整体对齐性能至关重要。

#### 伪标签数据的影响
我们进一步检查了辅助信息生成的初步对齐结果（即伪标签数据）的有用性。具体来说，我们用这些伪标签数据替换HGCN中的训练数据，得到HGCN-U，然后将其对齐结果与原始性能进行比较。对于F1分数，HGCN-U在DBP15KZH-EN上的分数比HGCN低4%，在DBP15KJA-EN上低2.9%，在DBP15KFR-EN上低2.8%。这种较小的差异验证了辅助信息生成的伪标签数据的有效性。这也表明，这种策略可以应用于其他监督或半监督框架，以减少它们对标注数据的依赖。

### 8.5 结论 (Conclusion)
在本章中，我们提出了一种能够处理不可对齐实体的无监督实体对齐（EA）解决方案。我们首先利用知识图谱（KG）的辅助信息生成初步的对齐结果，将这些结果视为伪标签数据，并将其输入到渐进学习框架中，以自训练的方式生成更好的KG嵌入和对齐结果。此外，我们设计了一个不可对齐实体预测模块来检测不可对齐的实体。实验结果验证了我们提出的模型的有效性及其相对于最先进方法的优越性。
