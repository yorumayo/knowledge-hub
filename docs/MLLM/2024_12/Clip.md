# Clip
> 标题 Learning Transferable Visual Models From Natural Language Supervision<br>
> [CLIP (Contrastive Language Image Pretraining)]<br>
> 作者: OpenAI<br>
> 发表: ICML 2021<br>
> 文章地址: https://arxiv.org/pdf/2103.00020<br>
> github: https://github.com/OpenAI/CLIP<br>
> 精读视频: (李沐)https://www.bilibili.com/video/BV1SL4y1s7LQ
---
## 1. 总结
基于**vision-language**，高效**zero-shot learning**的多模态预训练方法
## 2. 方法
### 2.1 1
