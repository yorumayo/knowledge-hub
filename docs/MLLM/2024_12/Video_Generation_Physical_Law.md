# Physical Law

> How Far is Video Generation from World Model: A Physical Law Perspective
> https://arxiv.org/abs/2411.02385<br>

## Abstract

1.  **研究背景与目标**
   - OpenAI的Sora展示了视频生成在开发符合基本物理定律的世界模型 (world model)方面的潜力.
   - 然而，视频生成模型 (video generation models)能否在没有人为先验 (human priors)的情况下，仅从视觉数据 (visual data)中发现这些物理定律值得质疑.
   - 一个学习了真实物理定律的世界模型应能对细微差异具有鲁棒性 (robustness)，并且能够在未见过的场景 (unseen scenarios)中做出正确的推断.


2.  **研究问题**
   - 在本工作中，我们在三个关键场景下评估了视频生成模型的表现：
     1.  **分布内场景 (in-distribution)**：模型在其训练数据分布内的表现.
     2.  **分布外场景 (out-of-distribution)**：模型在训练数据分布之外的场景中的表现.
     3.  **组合泛化 (combinatorial generalization)**：模型是否能够组合已有的知识来泛化到新的组合场景.

3.  **方法与实验平台**
   - 我们开发了一个二维 (2D)模拟测试平台，用于模拟物体运动和碰撞，以生成完全由一个或多个经典力学定律 (classical mechanics laws)确定的视频.
   - 该平台可以生成无限的数据，为大规模实验提供支持，并能够对生成的视频是否遵循物理定律进行定量评估 (quantitative evaluation).
   - 我们训练了基于扩散模型 (diffusion-based)的视频生成模型，根据初始帧 (initial frames)来预测物体的运动.

4.  **实验结果**
   - 扩展实验 (scaling experiments)的结果表明：
     1.  **分布内泛化 (in-distribution generalization)**：模型在分布内表现出完美的泛化能力.
     2.  **组合泛化 (combinatorial generalization)**：在组合泛化方面，模型表现出可测量的扩展行为 (scaling behavior).
     3.  **分布外泛化失败 (out-of-distribution failure)**：模型在分布外场景中表现较差，无法成功泛化.

5.  **进一步实验与关键见解**
   - 我们进行了进一步的实验，并得到了关于模型泛化机制的两个关键见解：
     1.  **基于案例的泛化行为 (case-based generalization behavior)**：模型未能抽象出普遍的物理规则，而是表现出“基于案例”的泛化行为，即倾向于模仿最接近的训练样本 (closest training example).
     2.  **优先级顺序**：在泛化到新的场景时，模型在参考训练数据时优先考虑不同的因素，优先级为：颜色 (color) > 尺寸 (size) > 速度 (velocity) > 形状 (shape).

6.  **结论**
   - 我们的研究表明，尽管在Sora的成功中扩展模型规模起到了重要作用，但仅依靠规模扩展不足以使视频生成模型发现基本物理定律.


## 1 INTRODUCTION

1.  **基础模型的兴起**
   - 基础模型 (Foundation models) (Bommasani et al. , 2021)通过将模型和数据扩展到前所未有的规模，展现了惊人的能力 (Brown, 2020; Kaplan et al. , 2020).
   - 例如，OpenAI的Sora (Brooks et al. , 2024)不仅能生成高保真、超现实的视频，还引发了对世界模型 (world models)研究的新热潮 (Yang et al. , 2023).

2.  **视频生成与物理世界模拟**
   - Sora报告 (Brooks et al. , 2024)中指出：“扩展视频生成模型是构建物理世界通用模拟器 (general-purpose simulators)的有前景的路径. ”
   - 世界模拟器 (World simulators)因其生成逼真数据和提供精确模拟的能力，正在机器人学 (robotics) (Yang et al. , 2023)和自动驾驶 (autonomous driving) (Hu et al. , 2023)领域引起广泛关注.
   - 这些模型需要理解基本的物理定律，以产生超越训练语料 (training corpus)范围的数据，并保证精确的模拟. 然而，视频生成是否可以仅通过观察视频来发现这些规则 (正如Sora所做的)仍然是一个未解的问题.
   - 我们的目标是进行系统研究，以理解扩展模型在物理定律发现中的关键作用和局限性.

3.  **模型泛化与物理法则学习的挑战**
   - 要确定视频生成模型是否真正学习了一种物理法则，而不仅仅是记住了数据，这具有很大挑战性.
   - 由于模型的内部知识是不可访问的，我们只能通过考察模型在未见过场景 (unseen scenarios)中的预测——即它的泛化能力 (generalization ability)——来推断模型的理解程度.
   - 我们在本文中提出了一种分类方法 (如图1所示)，用于基于训练数据和测试数据之间的关系进行全面评估.
     - **分布内泛化 (In-distribution, ID generalization)**：假设训练数据和测试数据是独立同分布 (i. i. d. ).
     - **分布外泛化 (Out-of-distribution, OOD generalization)**：指的是模型在来自不同于训练数据分布的测试数据上的表现，尤其是在隐含参数 (latent parameters)超出训练时的范围的情况下.
       - >（Latent Parameters）是指在数据中存在但通常不可直接观测或测量的变量，它们描述了数据的内在结构或特征. <br>
         > - 在许多模型中，数据的可见特征可能由一些隐藏的、不可见的因素所驱动. 隐含参数正是这些隐藏的因素. <br>
         > - 隐含参数通常是原始数据的低维度表示，它们用于捕获数据的关键特征和关系. 例如，在深度学习的自编码器（Autoencoder）中，隐含参数表示数据通过编码器后的压缩表示，保留了描述数据本质的重要信息.
     - 人类水平的物理推理可以轻松地进行分布外泛化 (OOD extrapolation)，并预测物理过程，而无需遇到完全相同的场景.
     - 另外，我们还考察了一种特殊的分布外能力，称为**组合泛化 (combinatorial generalization)**，它评估模型是否可以以新颖的方式结合两个不同的概念，这一特性通常被认为是基础模型在迈向人工通用智能 (AGI)过程中不可或缺的 (Du & Kaelbling, 2024).
     - > 分布外泛化关注的是数据分布的变化，而组合泛化关注的是已知概念的新组合. <br>
     - > 分布外泛化：如果一个模型在看到训练数据中存在的某个小球在左边滚动，那么测试它的分布外泛化能力可能是考察它在看到小球从右边滚动时的表现。这里的挑战在于小球的运动方向不同于训练数据，但小球的其他特征保持不变。<br>
     - > 组合泛化：如果模型见过红色的小球和蓝色的方块，组合泛化会评估模型是否可以理解蓝色的小球或红色的方块。这要求模型理解“颜色”和“形状”是可以独立组合的，而不仅仅是记住原有的固定组合。

<figure style="display: block; text-align: center;">   <img src="MLLM/2024_12/images/2024-11-26-19-40-35.png" at="name" style="display: block; margin: auto; width: 50%; height: auto;"></figure>

4.  **复杂对象与运动的挑战**
   - 实际视频通常包含复杂的、非刚性 (non-rigid)对象和运动，这对定量评估 (quantitative evaluation)甚至人工验证 (human validation)来说都是重大挑战.
   - 这类视频中的丰富纹理和外观可能成为混杂因素 (confounding factors)，使模型分散注意力，难以专注于物理规律本身.
   - 为了减轻这些问题的影响，我们特别聚焦于经典力学 (classical mechanics)，并开发了2D模拟器，其中对象由简单的几何形状表示. 每个视频展示这些二维对象的运动或碰撞，其行为完全由一个或两个基本物理定律决定，给定初始帧.
   - 该模拟器使我们能够生成大规模数据集，以支持视频生成模型的scaling.
   - 此外，我们开发了一种工具，用于从像素中推断生成视频中每个对象的内部状态 (internal states) (例如位置和大小)，从而为物理定律发现建立定量评估指标.

5.  **扩展实验与结果**
   - 我们首先研究了扩展视频生成模型如何影响分布内 (ID)和分布外 (OOD)的泛化能力.
   - 我们选择了三个基本的物理定律进行模拟：小球的匀速直线运动 (uniform linear motion)、两个小球的完全弹性碰撞 (perfectly elastic collision)、以及小球的抛物线运动 (parabolic motion).
   - 我们将数据集从3万 (30K)例扩展到300万 (3 million)例，同时将视频扩散模型的参数量从2200万 (22M)增加到3. 1亿 (310M).
   - 结果显示，模型在所有任务中均实现了接近完美的分布内泛化 (ID generalization). 然而，分布外泛化 (OOD generalization)的错误并未随着数据量和模型规模的增加而得到改善，暴露出扩展视频生成模型在处理分布外数据方面的局限性.
   - 对于组合泛化 (combinatorial generalization)，我们设计了一个环境，涉及多个对象的自由落体和碰撞，以研究它们的相互作用. 每次从八个对象中选取四个来创建一个视频，共有70种组合 (C4_8)可能性. 我们使用其中的60种进行训练，10种用于测试.
   - 我们通过改变训练数据量 (从60万到600万)来训练模型. 我们对生成的测试样本进行手动评估，如果视频在物理上看起来不合理，则将其标记为“异常” (abnormal).
   - 实验结果表明，扩展数据量显著降低了异常案例的百分比，从67%降至10%. 这表明扩展对于改善组合泛化至关重要.

6.  **泛化机制的深入分析**
   - 我们的实证分析揭示了视频生成模型泛化机制的两个有趣属性：
     1.  **基于案例的泛化偏差**：
        - 这些模型容易受到来自训练集的“欺骗性” ("deceptive")示例的影响，在某些情况下表现出基于案例 (case-based)的泛化行为.
        - 这种现象也出现在大型语言模型 (large language models) (Hu et al. , 2024)中，描述了模型在解决新任务时倾向于参考相似训练案例的倾向.
        - 例如，考虑一个训练有高速度小球匀速直线运动数据的视频模型. 如果通过水平翻转 (horizontal flipping)视频进行数据增强，从而引入反向运动，那么该模型可能会生成一个低速小球在初始帧后反向运动的场景，即便这种行为在物理上并不正确.
        - > 所以说，泛化程度不够的时候，数据增强可能会引入违背物理现实的情况
     2.  **数据属性的竞争优先级**：
        - 我们还探讨了不同数据属性在泛化过程中如何竞争. 例如，如果用于匀速运动训练的数据由红色小球和蓝色方块组成，那么模型可能会在条件帧后将一个红色方块立即变成小球.
        - 这种行为表明，模型优先考虑颜色 (color)而非形状 (shape). 我们的成对分析 (pairwise analysis)揭示了以下优先级层次：颜色 > 尺寸 (size) > 速度 (velocity) > 形状.
        - 这一排序可能解释了为什么当前的视频生成模型通常在保持对象一致性方面存在困难.

## 2 DISCOVERING PHYSICS LAWS WITH VIDEO GENERATION

### 2. 1 PROBLEM DEFINITION

1.  **研究目标与框架**
   - 在本节中，我们旨在建立一个框架，并定义在视频生成背景下物理定律发现的概念.
   - 在经典物理学中，物理定律通过数学方程表达，这些方程能够从初始条件预测未来状态和动态.
   - 在基于视频的观察领域，每一帧代表时间中的一个时刻，而物理定律的预测对应于在给定过去状态的条件下生成未来的帧.

2.  **物理过程与潜变量定义**
   - 考虑一个涉及若干潜在变量（latent variables）的物理过程，这些潜变量表示为 \( z = (z_1, z_2, \dots, z_k) \in Z \subseteq \mathbb{R}^k \)，每个变量代表某个物理参数，如速度（velocity）或位置（position）.
   - 根据经典力学，这些潜变量将通过微分方程 \( \dot{z} = F(z) \) 进行演化.
   - 在离散形式中，如果两个连续帧之间的时间间隔为 \( \delta \)，则有 \( z_{t+1} \approx z_t + \delta F(z_t) \).
   - 我们将渲染函数（rendering function）记作 \( R(\cdot) : Z \to \mathbb{R}^{3 \times H \times W} \)，用于将世界状态渲染为形状为 \( H \times W \) 的 RGB 图像.
   - 考虑一个由 \( L \) 帧组成的视频 \( V = \{I_1, I_2, \dots, I_L\} \)，其遵循经典力学动态.
   - 物理一致性（physical coherence）要求存在一系列满足以下条件的潜变量：
     1.  \( z_{t+1} = z_t + \delta F(z_t), \quad t = 1, \dots, L - 1 \)
     2.  \( I_t = R(z_t), \quad t = 1, \dots, L \)

3.  **视频生成模型的训练与物理一致性**
   - 我们训练一个由参数 \( \theta \) 表示的视频生成模型 \( p \)，其中 \( p_\theta(I_1, I_2, \dots, I_L) \) 描述了模型对视频帧的理解.
   - 我们可以通过从条件概率分布 \( p_\theta(I'_{c+1}, \dots, I'_L \mid I_1, \dots, I_c) \) 采样，基于初始帧的条件预测后续帧.
   - 变量 \( c \) 通常取值为 1 或 3，具体取决于任务的要求.
   - 因此，物理一致性损失（physical-coherence loss）可以简单地定义为 \( -\log p_\theta(I_{c+1}, \dots, I_L \mid I_1, \dots, I_c) \).
     - 它衡量了预测值符合真实世界发展的可能性.
     - 要准确预测后续帧，模型必须理解潜在的物理过程. 我们可以通过定量评估来判断视频生成模型是否正确发现并模拟了物理定律.
